{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "5130b50d102c3154"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:30.058492Z",
     "start_time": "2025-07-31T03:27:22.120588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "import data_prep\n",
    "from EDA import multicolin\n",
    "\n",
    "df_master = data_prep.prep_data('C:\\\\Users\\\\HP\\\\Downloads\\\\FiinProX_DE_Doanh_nghiep_20250721.xlsx')\n",
    "print(df_master.head())"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars_mini company platform  year        ebitda       revenue          cogs  \\\n",
      "0             NaN      NaN  2015           NaN           NaN           NaN   \n",
      "1             NaN      NaN  2016           NaN           NaN           NaN   \n",
      "2             NaN      NaN  2017           NaN           NaN           NaN   \n",
      "3             NaN      NaN  2018           NaN           NaN           NaN   \n",
      "4             NaN      NaN  2019  2.616088e+12  3.702945e+12 -1.006181e+12   \n",
      "\n",
      "vars_mini  sales_cost    admin_cost  net_op_profit  short_receive  ...  \\\n",
      "0                 NaN           NaN            NaN            NaN  ...   \n",
      "1                 NaN           NaN            NaN            NaN  ...   \n",
      "2                 NaN           NaN            NaN            NaN  ...   \n",
      "3                 NaN           NaN            NaN            NaN  ...   \n",
      "4                 0.0 -8.067600e+10   3.090044e+11   1.772164e+12  ...   \n",
      "\n",
      "vars_mini          cash   fixed_asset  other_long_asset          cwip  \\\n",
      "0                   NaN           NaN               NaN           NaN   \n",
      "1                   NaN           NaN               NaN           NaN   \n",
      "2                   NaN           NaN               NaN           NaN   \n",
      "3                   NaN           NaN               NaN           NaN   \n",
      "4          2.824210e+11  6.212330e+13       831781420.0  1.513467e+13   \n",
      "\n",
      "vars_mini  other_short_asset   long_invest   equity_fund   other_fund  \\\n",
      "0                        NaN           NaN           NaN          NaN   \n",
      "1                        NaN           NaN           NaN          NaN   \n",
      "2                        NaN           NaN           NaN          NaN   \n",
      "3                        NaN           NaN           NaN          NaN   \n",
      "4               1.017305e+12  4.405651e+11  9.264257e+12  124303566.0   \n",
      "\n",
      "vars_mini  gov_own  for_own  \n",
      "0              NaN      NaN  \n",
      "1              NaN      NaN  \n",
      "2              NaN      NaN  \n",
      "3              NaN      NaN  \n",
      "4              NaN      NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocess raw data",
   "id": "9741995e8540004a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main data",
   "id": "271d40d3fcf817d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:30.305961Z",
     "start_time": "2025-07-31T03:27:30.275309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for duplicate (no duplication)\n",
    "df_master.duplicated().sum()"
   ],
   "id": "8d7a6a4a78ece0d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:30.694252Z",
     "start_time": "2025-07-31T03:27:30.679672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop null 'company' (due to small number)\n",
    "df_master.dropna(subset=['company'], inplace=True)"
   ],
   "id": "bf2415ff4b8dbf68",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:30.905599Z",
     "start_time": "2025-07-31T03:27:30.876983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Data 1: Imbalanced data drop for and gov\n",
    "df_imbalanced = df_master.copy()\n",
    "df_imbal_noown = df_imbalanced.drop(columns=['for_own', 'gov_own'])\n",
    "df_imbal_noown.dropna(inplace=True)\n",
    "df_imbal_noown.shape"
   ],
   "id": "68aa2c721cb62101",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18700, 23)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- Many columns have weird values:\n",
    "    + revenue has negative values\n",
    "    + expenditure has negative values\n",
    "- This, however, is not recording error but rather due to intention. For example, customers require refund for products pruchased in the previous accounting period -> be accounted as sales return in this period -> negative revenue\n",
    "- On the other hand, reeceiving refund from seller would result in negative cost."
   ],
   "id": "6ddcb9c11550e94e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Backup data (opt)",
   "id": "fe47e21e44de710b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:30.923821Z",
     "start_time": "2025-07-31T03:27:30.912157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data 2 (backup): Imbalanced full col\n",
    "df_imbal_dropall = df_imbalanced.dropna()\n",
    "df_imbal_dropall.shape"
   ],
   "id": "47bf236e3484c8bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8073, 25)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:31.822486Z",
     "start_time": "2025-07-31T03:27:31.265307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data 3 (backup): Balanced (no gov and for own)\n",
    "df_balanced_noown = df_master.copy()\n",
    "df_balanced_noown.drop(columns=['for_own', 'gov_own'], inplace=True)\n",
    "\n",
    "\n",
    "'''\n",
    "    Drop all nulls\n",
    "'''\n",
    "result_dropallnull = []\n",
    "for idx, group in df_balanced_noown.groupby('company'):\n",
    "    if group.isna().sum().sum()>0:\n",
    "        continue\n",
    "    else:\n",
    "        result_dropallnull.append(group)\n",
    "\n",
    "df_bal_nonull = pd.concat(result_dropallnull, ignore_index=True)\n",
    "print(df_bal_nonull.shape)"
   ],
   "id": "1b11b4ea63bfc15a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12730, 23)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:31.888592Z",
     "start_time": "2025-07-31T03:27:31.872173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data 4: balanced full col\n",
    "df_balanced_full = df_master.copy()\n",
    "\n",
    "'''\n",
    "    Drop all nulls\n",
    "    Return nothing == all companies have some null when for and gov own exist\n",
    "'''\n"
   ],
   "id": "261786243d13937d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Drop all nulls\\n    Return nothing == all companies have some null when for and gov own exist\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EDA",
   "id": "c249e4d9264ac308"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:32.455808Z",
     "start_time": "2025-07-31T03:27:32.450650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data 1: (imbalance, no onwership)\n",
    "import EDA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "a8b5db9d111735c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:33.242242Z",
     "start_time": "2025-07-31T03:27:32.803587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# EDA\n",
    "'''\n",
    "    General trend of EBITDA over the year\n",
    "'''\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=df_imbal_noown, x='year', y='ebitda')"
   ],
   "id": "e393e7f8ffd500ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='year', ylabel='ebitda'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- Generally, ebitda went up slightly from 2015 to 2024\n",
    "- However, the light shade around the line also reveals high variance in ebitda of companies"
   ],
   "id": "ea9a3bd5541c8d7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:33.502447Z",
     "start_time": "2025-07-31T03:27:33.452317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "    Check for number of obs/quartile range\n",
    "'''\n",
    "for idx, group in df_imbal_noown.groupby('year'):\n",
    "    a = EDA.quartile_table(group, 'ebitda')\n",
    "    print(f'Year {idx}')\n",
    "    print(a)"
   ],
   "id": "5cb415112bfcc232",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2015\n",
      "  Quartile range  Num obs\n",
      "0             q1      490\n",
      "1             q2      490\n",
      "2             q3      490\n",
      "3             q4      490\n",
      "Year 2016\n",
      "  Quartile range  Num obs\n",
      "0             q1      550\n",
      "1             q2      549\n",
      "2             q3      549\n",
      "3             q4      550\n",
      "Year 2017\n",
      "  Quartile range  Num obs\n",
      "0             q1      558\n",
      "1             q2      529\n",
      "2             q3      543\n",
      "3             q4      544\n",
      "Year 2018\n",
      "  Quartile range  Num obs\n",
      "0             q1      541\n",
      "1             q2      541\n",
      "2             q3      541\n",
      "3             q4      541\n",
      "Year 2019\n",
      "  Quartile range  Num obs\n",
      "0             q1      450\n",
      "1             q2      449\n",
      "2             q3      449\n",
      "3             q4      450\n",
      "Year 2020\n",
      "  Quartile range  Num obs\n",
      "0             q1      440\n",
      "1             q2      440\n",
      "2             q3      440\n",
      "3             q4      440\n",
      "Year 2021\n",
      "  Quartile range  Num obs\n",
      "0             q1      430\n",
      "1             q2      429\n",
      "2             q3      429\n",
      "3             q4      430\n",
      "Year 2022\n",
      "  Quartile range  Num obs\n",
      "0             q1      430\n",
      "1             q2      429\n",
      "2             q3      429\n",
      "3             q4      430\n",
      "Year 2023\n",
      "  Quartile range  Num obs\n",
      "0             q1      410\n",
      "1             q2      408\n",
      "2             q3      408\n",
      "3             q4      409\n",
      "Year 2024\n",
      "  Quartile range  Num obs\n",
      "0             q1      394\n",
      "1             q2      392\n",
      "2             q3      392\n",
      "3             q4      393\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- Distribution of ebitda value of companies are spread equally among quartile ranges, in all years\n",
    "- This means data of ebitda has high variance among companies in every year"
   ],
   "id": "344f7c49183dcb9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:33.555753Z",
     "start_time": "2025-07-31T03:27:33.510842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "    Correlation with target variable\n",
    "'''\n",
    "df_imbal_noown.drop(columns=['company', 'platform']).corr()['ebitda']"
   ],
   "id": "6edd54fccbf1911d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vars_mini\n",
       "year                 0.019289\n",
       "ebitda               1.000000\n",
       "revenue              0.749819\n",
       "cogs                -0.807773\n",
       "sales_cost          -0.491252\n",
       "admin_cost          -0.764722\n",
       "net_op_profit        0.647062\n",
       "short_receive        0.551980\n",
       "in_stock             0.403575\n",
       "invest_nav           0.174400\n",
       "long_receive         0.423612\n",
       "long_liability       0.871524\n",
       "short_liability      0.678473\n",
       "cash                 0.787239\n",
       "fixed_asset          0.892432\n",
       "other_long_asset     0.507494\n",
       "cwip                 0.694640\n",
       "other_short_asset    0.517662\n",
       "long_invest          0.492669\n",
       "equity_fund          0.789879\n",
       "other_fund           0.020470\n",
       "Name: ebitda, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- cogs and admin_cost strongly correlate negatively with ebitda\n",
    "- fixed asset, long-liability, equity_fund, and cash are mostly positively correlated with ebitda"
   ],
   "id": "81efaf91a3ac0475"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:33.734379Z",
     "start_time": "2025-07-31T03:27:33.727743Z"
    }
   },
   "cell_type": "code",
   "source": "# Check for statistical issue (if any)",
   "id": "60503d074d5e5092",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Multicolinearity:\n",
    "- Variable with issue (4 most serious ones):\n",
    "    + fixed asset\n",
    "    + long_lia\n",
    "    + short_lia\n",
    "    + equity_fund\n",
    "- Consequence: reduce explainability of feature variables on target variables"
   ],
   "id": "4df81677775192d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:34.889232Z",
     "start_time": "2025-07-31T03:27:34.082519Z"
    }
   },
   "cell_type": "code",
   "source": "EDA.multicolin(df_imbal_noown)",
   "id": "20b026c2899587e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             features        VIF\n",
       "0                year   0.000002\n",
       "1              ebitda  25.130055\n",
       "2             revenue   6.208081\n",
       "3                cogs   8.247907\n",
       "4          sales_cost   2.640032\n",
       "5          admin_cost   6.039716\n",
       "6       net_op_profit  10.831798\n",
       "7       short_receive  17.714173\n",
       "8            in_stock   4.309120\n",
       "9          invest_nav   2.254587\n",
       "10       long_receive   6.768192\n",
       "11     long_liability  40.129386\n",
       "12    short_liability  34.881134\n",
       "13               cash  11.623373\n",
       "14        fixed_asset  56.453884\n",
       "15   other_long_asset   7.784380\n",
       "16               cwip   5.609301\n",
       "17  other_short_asset   8.669503\n",
       "18        long_invest   3.467397\n",
       "19        equity_fund  21.642707\n",
       "20         other_fund   1.035455"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ebitda</td>\n",
       "      <td>25.130055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revenue</td>\n",
       "      <td>6.208081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cogs</td>\n",
       "      <td>8.247907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sales_cost</td>\n",
       "      <td>2.640032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>admin_cost</td>\n",
       "      <td>6.039716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>net_op_profit</td>\n",
       "      <td>10.831798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>short_receive</td>\n",
       "      <td>17.714173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in_stock</td>\n",
       "      <td>4.309120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>invest_nav</td>\n",
       "      <td>2.254587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>long_receive</td>\n",
       "      <td>6.768192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>long_liability</td>\n",
       "      <td>40.129386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>short_liability</td>\n",
       "      <td>34.881134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cash</td>\n",
       "      <td>11.623373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fixed_asset</td>\n",
       "      <td>56.453884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>other_long_asset</td>\n",
       "      <td>7.784380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cwip</td>\n",
       "      <td>5.609301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>other_short_asset</td>\n",
       "      <td>8.669503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>long_invest</td>\n",
       "      <td>3.467397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>equity_fund</td>\n",
       "      <td>21.642707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>other_fund</td>\n",
       "      <td>1.035455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Heteeokedasticity:\n",
    "- low p-value indicates presence of hetereokedasticity\n",
    "- Consequences:\n",
    "    + reduce accuracy in linear models"
   ],
   "id": "fcc0ab13b94823ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:35.137389Z",
     "start_time": "2025-07-31T03:27:35.053706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EDA.hetereo(df = df_imbal_noown,\n",
    "            endog = 'ebitda',\n",
    "            num_drop = 'year')"
   ],
   "id": "f0556b6e01e5e71d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lagrange multiplier statistic', np.float64(2723.026409715606)),\n",
       " ('p-value', np.float64(0.0)),\n",
       " ('f-value', np.float64(167.56395678821184)),\n",
       " ('f p-value', np.float64(0.0))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- Since I focus on predicting the outcomes rather than intepreting feature importance, we can safely ignore multicolinearity\n",
    "- Hetereokedasticity, however, will be accounted for if the used model utilize linear regression."
   ],
   "id": "7e3450eede26515d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cross validation for optimal model",
   "id": "94b3ea3230033f85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Original",
   "id": "50c7b995e3823f49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:35.145618Z",
     "start_time": "2025-07-31T03:27:35.141639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data 1\n",
    "import train_test_pipeline as ttp\n",
    "from modelCV_exe import Execution as exe"
   ],
   "id": "93b0b2a30c948c57",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Task: Predict ebitda of companies in the list (forecasting problem)\n",
    "- Algorithm and Model choice (for the scope of this project, I'll limit my choice to most popular models and algorithms for forecasting problem):\n",
    "    - Support Vector Regression (SVR):\n",
    "        + Nonparametric: The algorithm does not assume the distribution of data. (Arnout Van Messem, 2019, https://doi.org/10.1016/bs.host.2019.08.003)\n",
    "        + Robust to outliers: at its core, SVR works only with \"hardest-to-be-classified\" data points, not caring about the whole dataset. Since, I did not treat outliers in EDA, this characteristic of SVR proves useful. (A.V.Messem, 2019)\n",
    "        + More, the algorithm can implicitly transform the data into linear problem (add dimensions) to self-improve without explicit programming. (A.V.Messem, 2019)\n",
    "\n",
    "    - XGBoost:\n",
    "\n",
    "        + Nonparametric\n",
    "        + Support regularization, significantly reduce the need for feature engineering (though it cannot account for cases for adding features with more explanation power, it can account for cases where features are redundant) -> beneficial when domain knowledge is limited\n",
    "        + Have been used in many panel data science researches (Shenlong Huang and Lingyun Hu, 2024; Reza Sotudeh et al., 2025; Jonathan Fuhr and Dominik Papies, 2024)\n",
    "\n",
    "    - Random Forest:\n",
    "\n",
    "        + Nonparametric\n",
    "        + Random forest train data on multiple subsets of data, each using distinct subset of features, reducing overfitting as a result\n",
    "        + However, normal RF model often assume independence among observations, violating panel data's structure. (Jianchang Hu and Silke Szymczak, 2023, https://doi.org/10.1093/bib/bbad002)\n"
   ],
   "id": "3d6d6bb2a752c949"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:35.529927Z",
     "start_time": "2025-07-31T03:27:35.501704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hold out set + input set + train + val sets\n",
    "    # drop platform col\n",
    "df_imbal_noown_inuse = df_imbal_noown.drop(columns=['platform'])\n",
    "\n",
    "    # setup data\n",
    "create_data = ttp.TrainTestPipe(data = df_imbal_noown_inuse)\n",
    "\n",
    "df_input, df_holdout, X_train, X_val, y_train, y_val = create_data.holdout_and_split(\n",
    "    panel_col = ['company', 'year'],\n",
    "    level = 1\n",
    ")\n",
    "\n",
    "    # Last check of data\n",
    "df_input.shape, df_holdout.shape, X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ],
   "id": "a0d6973245f1f346",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17127, 20), (1573, 20), (13772, 19), (3355, 19), (13772,), (3355,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Train_test_split follow instruction from (Augusto Cerqua et al., 2025 - https://ssrn.com/abstract=5014594).\n",
    "- The article instructed, for the problem of forecasting (forecast ebitda of companies in the future rather than predict out-of-sample entity), non-random split by time can be beneficial though at the expense of cross-sectional data leakage\n",
    "- However, since the main purpose is to forecast future value of existing companies, cross-sectional leakage might not be concerning issue (Augusto et al., 2025)"
   ],
   "id": "deb2d94411f765ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note:\n",
    "- Since different algorithms + hyper-params yield quite close scores, from now on, only XGBoost will be tested until satisfactory RMSE and MAPE are found (this aims to save computational capacity as XGBoost runs fast)"
   ],
   "id": "9340b65be4dba239"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:28:27.781445Z",
     "start_time": "2025-07-31T03:27:35.750386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cros-validation for best algorithm + hyper-parameter tuning\n",
    "cross_val = ttp.TrainTestPipe(data = df_imbal_noown_inuse)\n",
    "cross_val.hyper_parameter_tuning(n_splits=3, test_size=2)"
   ],
   "id": "a99553f551f4551f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XGBoost: ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   algo_used                                             params  mean_test_r2  \\\n",
       "13   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.845284   \n",
       "14   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.844803   \n",
       "11   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.842149   \n",
       "16   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.838585   \n",
       "17   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.837516   \n",
       "12   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.836970   \n",
       "10   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.836879   \n",
       "15   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.832318   \n",
       "33   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.824002   \n",
       "35   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.823980   \n",
       "34   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.823973   \n",
       "8    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.823073   \n",
       "26   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.823073   \n",
       "5    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.821950   \n",
       "23   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.821950   \n",
       "28   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.817535   \n",
       "30   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.816283   \n",
       "32   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.815725   \n",
       "31   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.815706   \n",
       "9    XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.815201   \n",
       "27   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.814716   \n",
       "29   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.806544   \n",
       "2    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.784573   \n",
       "20   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.784573   \n",
       "7    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.783704   \n",
       "25   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.783704   \n",
       "4    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.782014   \n",
       "22   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.782014   \n",
       "1    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.741911   \n",
       "19   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.741911   \n",
       "6    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.640240   \n",
       "24   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.640240   \n",
       "3    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.639066   \n",
       "21   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.639066   \n",
       "0    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.592595   \n",
       "18   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.592595   \n",
       "\n",
       "    mean_test_mape  mean_test_rmse  \n",
       "13    5.001238e+24    1.106833e+12  \n",
       "14    4.789280e+24    1.105208e+12  \n",
       "11    8.648460e+24    1.119312e+12  \n",
       "16    4.285617e+24    1.127338e+12  \n",
       "17    4.221602e+24    1.127934e+12  \n",
       "12    5.985376e+24    1.145643e+12  \n",
       "10    8.498268e+24    1.144178e+12  \n",
       "15    4.874151e+24    1.160917e+12  \n",
       "33    6.416685e+24    1.172940e+12  \n",
       "35    6.325833e+24    1.172786e+12  \n",
       "34    6.347295e+24    1.172810e+12  \n",
       "8     7.287712e+24    1.202679e+12  \n",
       "26    7.287712e+24    1.202679e+12  \n",
       "5     8.632701e+24    1.206665e+12  \n",
       "23    8.632701e+24    1.206665e+12  \n",
       "28    7.631376e+24    1.197069e+12  \n",
       "30    4.938309e+24    1.202842e+12  \n",
       "32    4.434221e+24    1.204215e+12  \n",
       "31    4.483364e+24    1.204291e+12  \n",
       "9     1.250130e+25    1.223968e+12  \n",
       "27    1.013721e+25    1.210659e+12  \n",
       "29    7.270106e+24    1.221980e+12  \n",
       "2     1.655159e+25    1.325154e+12  \n",
       "20    1.655159e+25    1.325154e+12  \n",
       "7     9.851824e+24    1.331507e+12  \n",
       "25    9.851824e+24    1.331507e+12  \n",
       "4     1.102398e+25    1.337082e+12  \n",
       "22    1.102398e+25    1.337082e+12  \n",
       "1     1.965294e+25    1.451486e+12  \n",
       "19    1.965294e+25    1.451486e+12  \n",
       "6     1.635106e+25    1.722808e+12  \n",
       "24    1.635106e+25    1.722808e+12  \n",
       "3     1.732577e+25    1.725750e+12  \n",
       "21    1.732577e+25    1.725750e+12  \n",
       "0     2.463185e+25    1.832100e+12  \n",
       "18    2.463185e+25    1.832100e+12  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_used</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_test_mape</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.845284</td>\n",
       "      <td>5.001238e+24</td>\n",
       "      <td>1.106833e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.844803</td>\n",
       "      <td>4.789280e+24</td>\n",
       "      <td>1.105208e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.842149</td>\n",
       "      <td>8.648460e+24</td>\n",
       "      <td>1.119312e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.838585</td>\n",
       "      <td>4.285617e+24</td>\n",
       "      <td>1.127338e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.837516</td>\n",
       "      <td>4.221602e+24</td>\n",
       "      <td>1.127934e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.836970</td>\n",
       "      <td>5.985376e+24</td>\n",
       "      <td>1.145643e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>8.498268e+24</td>\n",
       "      <td>1.144178e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.832318</td>\n",
       "      <td>4.874151e+24</td>\n",
       "      <td>1.160917e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.824002</td>\n",
       "      <td>6.416685e+24</td>\n",
       "      <td>1.172940e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.823980</td>\n",
       "      <td>6.325833e+24</td>\n",
       "      <td>1.172786e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.823973</td>\n",
       "      <td>6.347295e+24</td>\n",
       "      <td>1.172810e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.823073</td>\n",
       "      <td>7.287712e+24</td>\n",
       "      <td>1.202679e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.823073</td>\n",
       "      <td>7.287712e+24</td>\n",
       "      <td>1.202679e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.821950</td>\n",
       "      <td>8.632701e+24</td>\n",
       "      <td>1.206665e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.821950</td>\n",
       "      <td>8.632701e+24</td>\n",
       "      <td>1.206665e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.817535</td>\n",
       "      <td>7.631376e+24</td>\n",
       "      <td>1.197069e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.816283</td>\n",
       "      <td>4.938309e+24</td>\n",
       "      <td>1.202842e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.815725</td>\n",
       "      <td>4.434221e+24</td>\n",
       "      <td>1.204215e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.815706</td>\n",
       "      <td>4.483364e+24</td>\n",
       "      <td>1.204291e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.815201</td>\n",
       "      <td>1.250130e+25</td>\n",
       "      <td>1.223968e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.814716</td>\n",
       "      <td>1.013721e+25</td>\n",
       "      <td>1.210659e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.806544</td>\n",
       "      <td>7.270106e+24</td>\n",
       "      <td>1.221980e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.784573</td>\n",
       "      <td>1.655159e+25</td>\n",
       "      <td>1.325154e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.784573</td>\n",
       "      <td>1.655159e+25</td>\n",
       "      <td>1.325154e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.783704</td>\n",
       "      <td>9.851824e+24</td>\n",
       "      <td>1.331507e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.783704</td>\n",
       "      <td>9.851824e+24</td>\n",
       "      <td>1.331507e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.782014</td>\n",
       "      <td>1.102398e+25</td>\n",
       "      <td>1.337082e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.782014</td>\n",
       "      <td>1.102398e+25</td>\n",
       "      <td>1.337082e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.741911</td>\n",
       "      <td>1.965294e+25</td>\n",
       "      <td>1.451486e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.741911</td>\n",
       "      <td>1.965294e+25</td>\n",
       "      <td>1.451486e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.640240</td>\n",
       "      <td>1.635106e+25</td>\n",
       "      <td>1.722808e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.640240</td>\n",
       "      <td>1.635106e+25</td>\n",
       "      <td>1.722808e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>1.732577e+25</td>\n",
       "      <td>1.725750e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>1.732577e+25</td>\n",
       "      <td>1.725750e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.592595</td>\n",
       "      <td>2.463185e+25</td>\n",
       "      <td>1.832100e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.592595</td>\n",
       "      <td>2.463185e+25</td>\n",
       "      <td>1.832100e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment on run test (due to computational expense, only some hyper-params are tested):\n",
    "- Generally, R-squared of model is high, signifying model fits better line than simply guessing mean value\n",
    "- Despite that, RMSE and MAPE is still very high (the value of which is near predicted value (at 10^27)), signifying that predicted values are still very variant and not reliable.\n",
    "- Additional methods would be tried to improve this"
   ],
   "id": "37ef891e22970d32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Balanced data",
   "id": "349e929cc2c6a624"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What I'll do:\n",
    "- Change data structure to see if scores improve"
   ],
   "id": "b35b3d30066756ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:29:35.419880Z",
     "start_time": "2025-07-31T03:28:28.255416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-val for data 3\n",
    "crossval = exe(data=df_bal_nonull)\n",
    "crossval.execute(n_splits=4, test_size=2)"
   ],
   "id": "a1c9fddab4b91a27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XGBoost: ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   algo_used                                             params  mean_test_r2  \\\n",
       "12   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.852272   \n",
       "13   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.851737   \n",
       "15   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.851315   \n",
       "14   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.849906   \n",
       "16   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.847629   \n",
       "17   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.843776   \n",
       "33   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.838709   \n",
       "34   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.838628   \n",
       "35   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.838628   \n",
       "11   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.833930   \n",
       "10   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.832853   \n",
       "31   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.831238   \n",
       "32   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.831145   \n",
       "30   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.831100   \n",
       "9    XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.830079   \n",
       "8    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.828895   \n",
       "26   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.828895   \n",
       "5    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.828530   \n",
       "23   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.828530   \n",
       "27   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.808472   \n",
       "2    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.802268   \n",
       "20   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.802268   \n",
       "28   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.801575   \n",
       "29   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.798101   \n",
       "7    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.782420   \n",
       "25   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.782420   \n",
       "4    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.781866   \n",
       "22   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.781866   \n",
       "1    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.752294   \n",
       "19   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.752294   \n",
       "6    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.621159   \n",
       "24   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.621159   \n",
       "3    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.620565   \n",
       "21   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.620565   \n",
       "0    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.588396   \n",
       "18   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.588396   \n",
       "\n",
       "    mean_test_mape  mean_test_rmse  \n",
       "12    1.229508e+24    5.751677e+11  \n",
       "13    1.198497e+24    5.843715e+11  \n",
       "15    1.106692e+24    5.769376e+11  \n",
       "14    1.173178e+24    5.894107e+11  \n",
       "16    1.078864e+24    5.933994e+11  \n",
       "17    1.081205e+24    6.023436e+11  \n",
       "33    1.576861e+24    6.083409e+11  \n",
       "34    1.573098e+24    6.084851e+11  \n",
       "35    1.572907e+24    6.084865e+11  \n",
       "11    1.250482e+24    6.199129e+11  \n",
       "10    1.344930e+24    6.197448e+11  \n",
       "31    1.343761e+24    6.224468e+11  \n",
       "32    1.342727e+24    6.226292e+11  \n",
       "30    1.339669e+24    6.227625e+11  \n",
       "9     1.231277e+24    6.151180e+11  \n",
       "8     1.205181e+24    6.142377e+11  \n",
       "26    1.205181e+24    6.142377e+11  \n",
       "5     1.276094e+24    6.152291e+11  \n",
       "23    1.276094e+24    6.152291e+11  \n",
       "27    1.282528e+24    6.663956e+11  \n",
       "2     1.329978e+24    6.651987e+11  \n",
       "20    1.329978e+24    6.651987e+11  \n",
       "28    1.318277e+24    6.787081e+11  \n",
       "29    1.256172e+24    6.846920e+11  \n",
       "7     1.147950e+24    6.940910e+11  \n",
       "25    1.147950e+24    6.940910e+11  \n",
       "4     1.212923e+24    6.953127e+11  \n",
       "22    1.212923e+24    6.953127e+11  \n",
       "1     1.230835e+24    7.467164e+11  \n",
       "19    1.230835e+24    7.467164e+11  \n",
       "6     1.044734e+24    9.229793e+11  \n",
       "24    1.044734e+24    9.229793e+11  \n",
       "3     1.105877e+24    9.237597e+11  \n",
       "21    1.105877e+24    9.237597e+11  \n",
       "0     1.094788e+24    9.662501e+11  \n",
       "18    1.094788e+24    9.662501e+11  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_used</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_test_mape</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.852272</td>\n",
       "      <td>1.229508e+24</td>\n",
       "      <td>5.751677e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.851737</td>\n",
       "      <td>1.198497e+24</td>\n",
       "      <td>5.843715e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.851315</td>\n",
       "      <td>1.106692e+24</td>\n",
       "      <td>5.769376e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.849906</td>\n",
       "      <td>1.173178e+24</td>\n",
       "      <td>5.894107e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.847629</td>\n",
       "      <td>1.078864e+24</td>\n",
       "      <td>5.933994e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.843776</td>\n",
       "      <td>1.081205e+24</td>\n",
       "      <td>6.023436e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.838709</td>\n",
       "      <td>1.576861e+24</td>\n",
       "      <td>6.083409e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>1.573098e+24</td>\n",
       "      <td>6.084851e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>1.572907e+24</td>\n",
       "      <td>6.084865e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.833930</td>\n",
       "      <td>1.250482e+24</td>\n",
       "      <td>6.199129e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.832853</td>\n",
       "      <td>1.344930e+24</td>\n",
       "      <td>6.197448e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.831238</td>\n",
       "      <td>1.343761e+24</td>\n",
       "      <td>6.224468e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.831145</td>\n",
       "      <td>1.342727e+24</td>\n",
       "      <td>6.226292e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>1.339669e+24</td>\n",
       "      <td>6.227625e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.830079</td>\n",
       "      <td>1.231277e+24</td>\n",
       "      <td>6.151180e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.828895</td>\n",
       "      <td>1.205181e+24</td>\n",
       "      <td>6.142377e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.828895</td>\n",
       "      <td>1.205181e+24</td>\n",
       "      <td>6.142377e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.828530</td>\n",
       "      <td>1.276094e+24</td>\n",
       "      <td>6.152291e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.828530</td>\n",
       "      <td>1.276094e+24</td>\n",
       "      <td>6.152291e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.808472</td>\n",
       "      <td>1.282528e+24</td>\n",
       "      <td>6.663956e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.802268</td>\n",
       "      <td>1.329978e+24</td>\n",
       "      <td>6.651987e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.802268</td>\n",
       "      <td>1.329978e+24</td>\n",
       "      <td>6.651987e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.801575</td>\n",
       "      <td>1.318277e+24</td>\n",
       "      <td>6.787081e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.798101</td>\n",
       "      <td>1.256172e+24</td>\n",
       "      <td>6.846920e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.782420</td>\n",
       "      <td>1.147950e+24</td>\n",
       "      <td>6.940910e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.782420</td>\n",
       "      <td>1.147950e+24</td>\n",
       "      <td>6.940910e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.781866</td>\n",
       "      <td>1.212923e+24</td>\n",
       "      <td>6.953127e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.781866</td>\n",
       "      <td>1.212923e+24</td>\n",
       "      <td>6.953127e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>1.230835e+24</td>\n",
       "      <td>7.467164e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>1.230835e+24</td>\n",
       "      <td>7.467164e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.621159</td>\n",
       "      <td>1.044734e+24</td>\n",
       "      <td>9.229793e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.621159</td>\n",
       "      <td>1.044734e+24</td>\n",
       "      <td>9.229793e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.620565</td>\n",
       "      <td>1.105877e+24</td>\n",
       "      <td>9.237597e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.620565</td>\n",
       "      <td>1.105877e+24</td>\n",
       "      <td>9.237597e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.588396</td>\n",
       "      <td>1.094788e+24</td>\n",
       "      <td>9.662501e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.588396</td>\n",
       "      <td>1.094788e+24</td>\n",
       "      <td>9.662501e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- Significant improvements are seen when data is balanced:\n",
    "    + Improved R-squared for top 2 XGBoost\n",
    "    + RMSE decreased by ~45%\n",
    "    + MAPE decreased by ~78%\n",
    "- However, RMSE and MAPE is still high"
   ],
   "id": "1631b7c3fd420fd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Scaling + delete outlier",
   "id": "200fc7cc88aaa218"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What I'll do:\n",
    "- Detect abnormal EBITDA datapoints for deletion\n",
    "- Scale EBITDA to decrease variance"
   ],
   "id": "119695ca01f8b0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Outlier treatment",
   "id": "8062fb280b6fcff6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:30:32.541058Z",
     "start_time": "2025-07-31T03:29:36.130110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Outliers deletion IQR method\n",
    "# Loss check\n",
    "bf = df_imbal_noown_inuse\n",
    "af = df_imbal_noown_inuse[\n",
    "    (df_imbal_noown_inuse['ebitda']<=bf['ebitda'].quantile(.75))&\n",
    "    (df_imbal_noown_inuse['ebitda']>=bf['ebitda'].quantile(.25))]\n",
    "print(f'Before drop: {bf.shape[0]}')\n",
    "print(f'After drop: {af.shape[0]}')\n",
    "print(f'Loss: {bf.shape[0]-af.shape[0]}')\n",
    "\n",
    "# Data without outlier\n",
    "no_outlier = exe(data=af)\n",
    "no_outlier.execute(n_splits=4, test_size=2)"
   ],
   "id": "ef3438b8c2b87b54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: 18700\n",
      "After drop: 9350\n",
      "Loss: 9350\n",
      "Processing XGBoost: ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- MAPE improves significantly -> on average, predicted value is 40% off actual value\n",
    "- RMSE also improved by >10 times.\n",
    "- This came with a little decrease in R-squared and half the data dropped"
   ],
   "id": "ca98a44f384a3f4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scale target variable (ebitda)",
   "id": "dd9e3dd3783c2318"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:42:51.551770Z",
     "start_time": "2025-07-31T02:41:15.002110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scale with sign log transformation\n",
    "\n",
    "# Formula: sign(-/+)*log(|y|+1)\n",
    "import numpy as np\n",
    "df_ln = df_imbal_noown_inuse.copy()\n",
    "df_ln['ebitda_trans'] = df_ln['ebitda'].apply(\n",
    "    lambda x: np.sign(x)*np.log1p(abs(x)))\n",
    "name_map = {\n",
    "    'ebitda': 'ebitda_ori',\n",
    "    'ebitda_trans': 'ebitda'\n",
    "}\n",
    "df_ln = df_ln.rename(columns=name_map)\n",
    "\n",
    "scale_log = exe(data=df_ln.drop(columns='ebitda_ori'))\n",
    "scale_log.execute(n_splits=4, test_size=2)"
   ],
   "id": "6da74dddcb448fc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XGBoost: ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   algo_used                                             params  mean_test_r2  \\\n",
       "17   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.669612   \n",
       "16   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.668828   \n",
       "13   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.668110   \n",
       "15   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.667692   \n",
       "14   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.667039   \n",
       "12   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.665773   \n",
       "8    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.664949   \n",
       "26   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.664949   \n",
       "5    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.658632   \n",
       "23   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.658632   \n",
       "7    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.643491   \n",
       "25   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.643491   \n",
       "4    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.635482   \n",
       "22   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.635482   \n",
       "30   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.609988   \n",
       "31   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.606852   \n",
       "32   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.605450   \n",
       "33   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.570535   \n",
       "34   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.570186   \n",
       "35   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.570144   \n",
       "10   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.569888   \n",
       "9    XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.559703   \n",
       "11   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.554038   \n",
       "6    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.547329   \n",
       "24   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.547329   \n",
       "3    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.536379   \n",
       "21   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.536379   \n",
       "2    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.534726   \n",
       "20   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.534726   \n",
       "27   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.502877   \n",
       "1    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.497435   \n",
       "19   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.497435   \n",
       "29   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.492677   \n",
       "28   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.488998   \n",
       "0    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.396776   \n",
       "18   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.396776   \n",
       "\n",
       "    mean_test_mape  mean_test_rmse  \n",
       "17    9.454582e+14        9.267242  \n",
       "16    9.569671e+14        9.278158  \n",
       "13    8.660641e+14        9.289596  \n",
       "15    7.684761e+14        9.294451  \n",
       "14    1.021333e+15        9.303615  \n",
       "12    7.080012e+14        9.322963  \n",
       "8     9.875691e+14        9.331561  \n",
       "26    9.875691e+14        9.331561  \n",
       "5     9.900706e+14        9.421422  \n",
       "23    9.900706e+14        9.421422  \n",
       "7     1.569770e+15        9.624324  \n",
       "25    1.569770e+15        9.624324  \n",
       "4     1.522853e+15        9.734828  \n",
       "22    1.522853e+15        9.734828  \n",
       "30    5.470615e+14       10.071569  \n",
       "31    5.092736e+14       10.112821  \n",
       "32    4.986813e+14       10.131450  \n",
       "33    2.516468e+15       10.539978  \n",
       "34    2.519875e+15       10.544292  \n",
       "35    2.519732e+15       10.544867  \n",
       "10    2.987610e+15       10.542040  \n",
       "9     2.659360e+15       10.686747  \n",
       "11    3.624420e+15       10.684380  \n",
       "6     2.437240e+15       10.842885  \n",
       "24    2.437240e+15       10.842885  \n",
       "3     2.470666e+15       10.975547  \n",
       "21    2.470666e+15       10.975547  \n",
       "2     2.804322e+15       10.986686  \n",
       "20    2.804322e+15       10.986686  \n",
       "27    4.572458e+15       11.156914  \n",
       "1     2.976324e+15       11.418767  \n",
       "19    2.976324e+15       11.418767  \n",
       "29    4.852708e+15       11.205406  \n",
       "28    4.904730e+15       11.249358  \n",
       "0     3.367093e+15       12.516318  \n",
       "18    3.367093e+15       12.516318  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_used</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_test_mape</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.669612</td>\n",
       "      <td>9.454582e+14</td>\n",
       "      <td>9.267242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.668828</td>\n",
       "      <td>9.569671e+14</td>\n",
       "      <td>9.278158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.668110</td>\n",
       "      <td>8.660641e+14</td>\n",
       "      <td>9.289596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.667692</td>\n",
       "      <td>7.684761e+14</td>\n",
       "      <td>9.294451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.667039</td>\n",
       "      <td>1.021333e+15</td>\n",
       "      <td>9.303615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.665773</td>\n",
       "      <td>7.080012e+14</td>\n",
       "      <td>9.322963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.664949</td>\n",
       "      <td>9.875691e+14</td>\n",
       "      <td>9.331561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.664949</td>\n",
       "      <td>9.875691e+14</td>\n",
       "      <td>9.331561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.658632</td>\n",
       "      <td>9.900706e+14</td>\n",
       "      <td>9.421422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.658632</td>\n",
       "      <td>9.900706e+14</td>\n",
       "      <td>9.421422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.643491</td>\n",
       "      <td>1.569770e+15</td>\n",
       "      <td>9.624324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.643491</td>\n",
       "      <td>1.569770e+15</td>\n",
       "      <td>9.624324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.635482</td>\n",
       "      <td>1.522853e+15</td>\n",
       "      <td>9.734828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.635482</td>\n",
       "      <td>1.522853e+15</td>\n",
       "      <td>9.734828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.609988</td>\n",
       "      <td>5.470615e+14</td>\n",
       "      <td>10.071569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.606852</td>\n",
       "      <td>5.092736e+14</td>\n",
       "      <td>10.112821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.605450</td>\n",
       "      <td>4.986813e+14</td>\n",
       "      <td>10.131450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.570535</td>\n",
       "      <td>2.516468e+15</td>\n",
       "      <td>10.539978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.570186</td>\n",
       "      <td>2.519875e+15</td>\n",
       "      <td>10.544292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.570144</td>\n",
       "      <td>2.519732e+15</td>\n",
       "      <td>10.544867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.569888</td>\n",
       "      <td>2.987610e+15</td>\n",
       "      <td>10.542040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.559703</td>\n",
       "      <td>2.659360e+15</td>\n",
       "      <td>10.686747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.554038</td>\n",
       "      <td>3.624420e+15</td>\n",
       "      <td>10.684380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.547329</td>\n",
       "      <td>2.437240e+15</td>\n",
       "      <td>10.842885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.547329</td>\n",
       "      <td>2.437240e+15</td>\n",
       "      <td>10.842885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.536379</td>\n",
       "      <td>2.470666e+15</td>\n",
       "      <td>10.975547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.536379</td>\n",
       "      <td>2.470666e+15</td>\n",
       "      <td>10.975547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.534726</td>\n",
       "      <td>2.804322e+15</td>\n",
       "      <td>10.986686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.534726</td>\n",
       "      <td>2.804322e+15</td>\n",
       "      <td>10.986686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.502877</td>\n",
       "      <td>4.572458e+15</td>\n",
       "      <td>11.156914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.497435</td>\n",
       "      <td>2.976324e+15</td>\n",
       "      <td>11.418767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.497435</td>\n",
       "      <td>2.976324e+15</td>\n",
       "      <td>11.418767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.492677</td>\n",
       "      <td>4.852708e+15</td>\n",
       "      <td>11.205406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.488998</td>\n",
       "      <td>4.904730e+15</td>\n",
       "      <td>11.249358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.396776</td>\n",
       "      <td>3.367093e+15</td>\n",
       "      <td>12.516318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.396776</td>\n",
       "      <td>3.367093e+15</td>\n",
       "      <td>12.516318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- R-squared decreased compare to outlier-treated and original data\n",
    "- However, MAPE decreased compared to original data (though way larger than outlier treated)\n",
    "- This proves scaling with log does improve high variance issue"
   ],
   "id": "b5df956f3625d5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:43:55.949560Z",
     "start_time": "2025-07-31T02:42:51.730554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scale with yeo-johnson method\n",
    "\n",
    "# Set up data\n",
    "df_yeo = df_imbal_noown_inuse.copy()\n",
    "spliter = ttp.TrainTestPipe(data=df_yeo)\n",
    "df_yeo_input = spliter.holdout_and_split(panel_col=['company', 'year'], level=1)[0]\n",
    "\n",
    "# cross validation with yeo-johnson transformed target var\n",
    "from panelsplit.cross_validation import PanelSplit\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import root_mean_squared_error as rmse, mean_absolute_percentage_error as mape, r2_score as r2\n",
    "import hyparam_testingmodel as hp\n",
    "from itertools import product\n",
    "from statistics import mean\n",
    "\n",
    "periods = df_yeo_input.index.get_level_values(1)\n",
    "panel_split = PanelSplit(periods = periods, n_splits = 4, test_size = 2)\n",
    "all_splits = panel_split.split()\n",
    "\n",
    "\n",
    "# param-mix\n",
    "key, value = zip(*hp.param_xg.items())\n",
    "for v in product(*value):\n",
    "    params = dict(zip(key, v))\n",
    "\n",
    "    rmse_sc = []\n",
    "    mape_sc = []\n",
    "    r2_sc = []\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for tr_idx, val_idx in all_splits:\n",
    "        X_tr, y_tr = df_yeo_input.drop(columns='ebitda').loc[tr_idx], df_yeo_input['ebitda'].loc[tr_idx]\n",
    "        X_val, y_val = df_yeo_input.drop(columns='ebitda').loc[val_idx], df_yeo_input['ebitda'].loc[val_idx]\n",
    "\n",
    "        # yeo-johnson transdormed\n",
    "        yeo_trans = PowerTransformer(method = 'yeo-johnson', standardize = False) # do not change distribution (just skewness)\n",
    "        y_tr_trans = yeo_trans.fit_transform(y_tr.values.reshape(-1,1))\n",
    "        y_val_trans = yeo_trans.transform(y_val.values.reshape(-1,1))\n",
    "\n",
    "        # Run model\n",
    "        xgb_reg = XGBRegressor(**params)\n",
    "        xgb_reg.fit(X_tr, y_tr_trans)\n",
    "        y_pred = xgb_reg.predict(X_val)\n",
    "\n",
    "        # Scoring\n",
    "        root_mse_score = rmse(y_pred, y_val_trans)\n",
    "        mean_ape_score = mape(y_pred, y_val_trans)\n",
    "        r_squared_score = r2(y_pred, y_val_trans)\n",
    "\n",
    "        rmse_sc.append(root_mse_score)\n",
    "        mape_sc.append(mean_ape_score)\n",
    "        r2_sc.append(r_squared_score)\n",
    "\n",
    "\n",
    "    param_rmse = mean(rmse_sc)\n",
    "    param_mape = mean(mape_sc)\n",
    "    param_r2 = mean(r2_sc)\n",
    "\n",
    "    print(f'Parameters: {params} with rmse: {param_rmse:,.2f}, mape: {param_mape:,.2f}, r2: {param_r2:,.2f}')\n"
   ],
   "id": "6fc6b4a11ba45c6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 2, 'subsample': 0.5} with rmse: 768,788,694,171.58, mape: 2.18, r2: -19.73\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 6, 'subsample': 0.5} with rmse: 744,381,517,766.10, mape: 1.98, r2: -15.85\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.5} with rmse: 742,488,844,073.85, mape: 2.32, r2: -15.67\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 2, 'subsample': 0.5} with rmse: 726,505,815,191.76, mape: 2.05, r2: -3.94\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 6, 'subsample': 0.5} with rmse: 698,661,833,957.31, mape: 2.57, r2: -3.34\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 10, 'subsample': 0.5} with rmse: 698,590,853,854.02, mape: 2.47, r2: -3.44\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 2, 'subsample': 0.5} with rmse: 768,788,694,171.58, mape: 2.18, r2: -19.73\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 6, 'subsample': 0.5} with rmse: 744,381,517,766.10, mape: 1.98, r2: -15.85\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.5} with rmse: 742,488,844,073.85, mape: 2.32, r2: -15.67\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 2, 'subsample': 0.5} with rmse: 837,955,871,726.87, mape: 2.76, r2: -2.70\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 6, 'subsample': 0.5} with rmse: 746,388,264,480.50, mape: 4.32, r2: -2.98\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 10, 'subsample': 0.5} with rmse: 729,488,257,411.89, mape: 2.49, r2: -3.05\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 2, 'subsample': 0.5} with rmse: 730,646,720,947.43, mape: 2.28, r2: -7.90\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 6, 'subsample': 0.5} with rmse: 706,017,603,810.47, mape: 1.73, r2: -6.51\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.5} with rmse: 704,426,672,679.04, mape: 2.14, r2: -6.44\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 2, 'subsample': 0.5} with rmse: 762,832,847,886.70, mape: 2.45, r2: -3.22\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 6, 'subsample': 0.5} with rmse: 708,920,678,864.44, mape: 66.24, r2: -2.96\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 10, 'subsample': 0.5} with rmse: 711,034,552,717.27, mape: 3.41, r2: -3.02\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 2, 'subsample': 0.5} with rmse: 730,646,720,947.43, mape: 2.28, r2: -7.90\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 6, 'subsample': 0.5} with rmse: 706,017,603,810.47, mape: 1.73, r2: -6.51\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.5} with rmse: 704,426,672,679.04, mape: 2.14, r2: -6.44\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.3, 'max_depth': 2, 'subsample': 0.5} with rmse: 833,466,700,536.61, mape: 2.41, r2: -2.57\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.3, 'max_depth': 6, 'subsample': 0.5} with rmse: 745,933,838,111.27, mape: 2.03, r2: -2.98\n",
      "Parameters: {'n_estimators': 200, 'learning_rate': 0.3, 'max_depth': 10, 'subsample': 0.5} with rmse: 729,728,519,136.87, mape: 2.50, r2: -3.05\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 2, 'subsample': 0.5} with rmse: 719,404,672,637.51, mape: 2.39, r2: -5.35\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 6, 'subsample': 0.5} with rmse: 696,479,763,212.10, mape: 4.00, r2: -4.46\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.5} with rmse: 695,164,224,318.75, mape: 3.41, r2: -4.45\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 2, 'subsample': 0.5} with rmse: 765,697,722,602.14, mape: 2.47, r2: -2.94\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 6, 'subsample': 0.5} with rmse: 712,332,700,984.48, mape: 9.31, r2: -2.90\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 10, 'subsample': 0.5} with rmse: 714,908,011,582.78, mape: 1.73, r2: -2.96\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 2, 'subsample': 0.5} with rmse: 719,404,672,637.51, mape: 2.39, r2: -5.35\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 6, 'subsample': 0.5} with rmse: 696,479,763,212.10, mape: 4.00, r2: -4.46\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.5} with rmse: 695,164,224,318.75, mape: 3.41, r2: -4.45\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.3, 'max_depth': 2, 'subsample': 0.5} with rmse: 836,676,119,549.28, mape: 5.44, r2: -2.54\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.3, 'max_depth': 6, 'subsample': 0.5} with rmse: 745,792,364,605.23, mape: 2.08, r2: -2.97\n",
      "Parameters: {'n_estimators': 300, 'learning_rate': 0.3, 'max_depth': 10, 'subsample': 0.5} with rmse: 729,725,492,335.70, mape: 3.10, r2: -3.05\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- yeo-johnson proves ineffective, making prediction worse"
   ],
   "id": "e08e1b7943ddef51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature engineer",
   "id": "bb8f84af71bda65c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What I'll do:\n",
    "- Add lag features to capture temporal factor in the data\n",
    "- Risk: many companies only have 1 - 2 years of data -> data loss when lagged\n",
    "- Lag vars:\n",
    "    + test with lagged ebitda\n",
    "    + test with lagged features which have high correlation with ebitda"
   ],
   "id": "287eec828e6bf5f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:43:56.315754Z",
     "start_time": "2025-07-31T02:43:56.303372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import create_lag\n",
    "# used data\n",
    "df_lag_imbal = df_imbal_noown_inuse.copy()\n",
    "\n",
    "# features and var list\n",
    "# target var\n",
    "var_tar = ['ebitda']\n",
    "\n",
    "# correlation > 50\n",
    "vars_high_corr = ['fixed_asset', 'long_liability', 'equity_fund', 'cash', 'revenue', 'cwip', 'short_liability', 'net_op_profit', 'short_receive', 'other_short_asset', 'other_long_asset', 'long_invest', 'admin_cost', 'cogs']\n",
    "\n",
    "# correlation < 50\n",
    "vars_low_corr = ['long_receive', 'in_stock', 'sales_cost']\n",
    "\n",
    "# all features and target\n",
    "vars_all = ['ebitda', 'fixed_asset', 'long_liability', 'equity_fund', 'cash', 'revenue', 'cwip', 'short_liability', 'net_op_profit', 'short_receive', 'other_short_asset', 'other_long_asset', 'long_invest', 'long_receive', 'in_stock', 'sales_cost', 'admin_cost', 'cogs']"
   ],
   "id": "4a63ed9804442b83",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:43:59.450944Z",
     "start_time": "2025-07-31T02:43:56.561623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test all lags\n",
    "df_lagged = create_lag.create_lag(df = df_imbal_noown_inuse,\n",
    "                                        id_col = 'company',\n",
    "                                        time_col = 'year',\n",
    "                                        cols = var_tar,\n",
    "                                        lag_num = 3)\n",
    "df_lagged.shape"
   ],
   "id": "6cb7edd8486273d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11370, 25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:44:54.783493Z",
     "start_time": "2025-07-31T02:43:59.756469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cros_val_lag = exe(data=df_lagged)\n",
    "cros_val_lag.execute(n_splits=3, test_size = 1)"
   ],
   "id": "dc2051db1ba4f672",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XGBoost: ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   algo_used                                             params  mean_test_r2  \\\n",
       "14   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.881694   \n",
       "17   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.881476   \n",
       "16   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.879963   \n",
       "13   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.879217   \n",
       "11   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.873946   \n",
       "15   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...      0.873289   \n",
       "12   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...      0.872154   \n",
       "35   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.871328   \n",
       "34   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.871314   \n",
       "33   XGBoost  {'learning_rate': 0.3, 'max_depth': 10, 'n_est...      0.870650   \n",
       "10   XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.868749   \n",
       "9    XGBoost  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...      0.862361   \n",
       "8    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.855559   \n",
       "26   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.855559   \n",
       "5    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.855459   \n",
       "23   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.855459   \n",
       "32   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.851483   \n",
       "31   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.851468   \n",
       "30   XGBoost  {'learning_rate': 0.3, 'max_depth': 6, 'n_esti...      0.850023   \n",
       "2    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.842588   \n",
       "20   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.842588   \n",
       "27   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.830424   \n",
       "28   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.822106   \n",
       "29   XGBoost  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...      0.813021   \n",
       "7    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.807959   \n",
       "25   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.807959   \n",
       "4    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.807798   \n",
       "22   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.807798   \n",
       "1    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.790930   \n",
       "19   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.790930   \n",
       "3    XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.647744   \n",
       "21   XGBoost  {'learning_rate': 0.01, 'max_depth': 6, 'n_est...      0.647744   \n",
       "6    XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.647660   \n",
       "24   XGBoost  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...      0.647660   \n",
       "0    XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.630514   \n",
       "18   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...      0.630514   \n",
       "\n",
       "    mean_test_mape  mean_test_rmse  \n",
       "14    2.366655e+24    1.008014e+12  \n",
       "17    3.225765e+24    1.005815e+12  \n",
       "16    3.153131e+24    1.010209e+12  \n",
       "13    2.487322e+24    1.016867e+12  \n",
       "11    3.344764e+24    1.039894e+12  \n",
       "15    1.451523e+24    1.038209e+12  \n",
       "12    1.335080e+24    1.045813e+12  \n",
       "35    5.912055e+24    1.043748e+12  \n",
       "34    5.913710e+24    1.043802e+12  \n",
       "33    5.967052e+24    1.046298e+12  \n",
       "10    4.421246e+24    1.063036e+12  \n",
       "9     8.741715e+24    1.088448e+12  \n",
       "8     1.842052e+24    1.115649e+12  \n",
       "26    1.842052e+24    1.115649e+12  \n",
       "5     2.171291e+24    1.116109e+12  \n",
       "23    2.171291e+24    1.116109e+12  \n",
       "32    2.314128e+24    1.117869e+12  \n",
       "31    2.321588e+24    1.117950e+12  \n",
       "30    2.436958e+24    1.122884e+12  \n",
       "2     9.636648e+24    1.164894e+12  \n",
       "20    9.636648e+24    1.164894e+12  \n",
       "27    5.768485e+24    1.207477e+12  \n",
       "28    5.337003e+24    1.216748e+12  \n",
       "29    6.525138e+24    1.234867e+12  \n",
       "7     2.354453e+24    1.290091e+12  \n",
       "25    2.354453e+24    1.290091e+12  \n",
       "4     2.663211e+24    1.290587e+12  \n",
       "22    2.663211e+24    1.290587e+12  \n",
       "1     8.559322e+24    1.344594e+12  \n",
       "19    8.559322e+24    1.344594e+12  \n",
       "3     2.545637e+24    1.750113e+12  \n",
       "21    2.545637e+24    1.750113e+12  \n",
       "6     2.428639e+24    1.750328e+12  \n",
       "24    2.428639e+24    1.750328e+12  \n",
       "0     5.926976e+24    1.792297e+12  \n",
       "18    5.926976e+24    1.792297e+12  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_used</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_test_mape</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>2.366655e+24</td>\n",
       "      <td>1.008014e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.881476</td>\n",
       "      <td>3.225765e+24</td>\n",
       "      <td>1.005815e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.879963</td>\n",
       "      <td>3.153131e+24</td>\n",
       "      <td>1.010209e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.879217</td>\n",
       "      <td>2.487322e+24</td>\n",
       "      <td>1.016867e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.873946</td>\n",
       "      <td>3.344764e+24</td>\n",
       "      <td>1.039894e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>1.451523e+24</td>\n",
       "      <td>1.038209e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.872154</td>\n",
       "      <td>1.335080e+24</td>\n",
       "      <td>1.045813e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.871328</td>\n",
       "      <td>5.912055e+24</td>\n",
       "      <td>1.043748e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.871314</td>\n",
       "      <td>5.913710e+24</td>\n",
       "      <td>1.043802e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.870650</td>\n",
       "      <td>5.967052e+24</td>\n",
       "      <td>1.046298e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.868749</td>\n",
       "      <td>4.421246e+24</td>\n",
       "      <td>1.063036e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.862361</td>\n",
       "      <td>8.741715e+24</td>\n",
       "      <td>1.088448e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.855559</td>\n",
       "      <td>1.842052e+24</td>\n",
       "      <td>1.115649e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.855559</td>\n",
       "      <td>1.842052e+24</td>\n",
       "      <td>1.115649e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.855459</td>\n",
       "      <td>2.171291e+24</td>\n",
       "      <td>1.116109e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.855459</td>\n",
       "      <td>2.171291e+24</td>\n",
       "      <td>1.116109e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.851483</td>\n",
       "      <td>2.314128e+24</td>\n",
       "      <td>1.117869e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.851468</td>\n",
       "      <td>2.321588e+24</td>\n",
       "      <td>1.117950e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>0.850023</td>\n",
       "      <td>2.436958e+24</td>\n",
       "      <td>1.122884e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.842588</td>\n",
       "      <td>9.636648e+24</td>\n",
       "      <td>1.164894e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.842588</td>\n",
       "      <td>9.636648e+24</td>\n",
       "      <td>1.164894e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.830424</td>\n",
       "      <td>5.768485e+24</td>\n",
       "      <td>1.207477e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.822106</td>\n",
       "      <td>5.337003e+24</td>\n",
       "      <td>1.216748e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.813021</td>\n",
       "      <td>6.525138e+24</td>\n",
       "      <td>1.234867e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.807959</td>\n",
       "      <td>2.354453e+24</td>\n",
       "      <td>1.290091e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.807959</td>\n",
       "      <td>2.354453e+24</td>\n",
       "      <td>1.290091e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.807798</td>\n",
       "      <td>2.663211e+24</td>\n",
       "      <td>1.290587e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.807798</td>\n",
       "      <td>2.663211e+24</td>\n",
       "      <td>1.290587e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.790930</td>\n",
       "      <td>8.559322e+24</td>\n",
       "      <td>1.344594e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.790930</td>\n",
       "      <td>8.559322e+24</td>\n",
       "      <td>1.344594e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.647744</td>\n",
       "      <td>2.545637e+24</td>\n",
       "      <td>1.750113e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.647744</td>\n",
       "      <td>2.545637e+24</td>\n",
       "      <td>1.750113e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.647660</td>\n",
       "      <td>2.428639e+24</td>\n",
       "      <td>1.750328e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.647660</td>\n",
       "      <td>2.428639e+24</td>\n",
       "      <td>1.750328e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.630514</td>\n",
       "      <td>5.926976e+24</td>\n",
       "      <td>1.792297e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.630514</td>\n",
       "      <td>5.926976e+24</td>\n",
       "      <td>1.792297e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- R-squared improved with lagged var\n",
    "- MAPE also improved by at least 2 times\n",
    "- RMSE, however, does not improve"
   ],
   "id": "edc8fc0de593a8a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final model",
   "id": "79ae87627640795d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Final model used data:\n",
    "- balanced (companies having the same years recorded)\n",
    "- Then, dropping all outliers (may make the data unbalanced again)\n",
    "- Lag ebitda (target var) by three years"
   ],
   "id": "516b9dfa0c4b0662"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:27:18.366628Z",
     "start_time": "2025-07-31T02:44:55.211625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# outlier drop (scale) + balance\n",
    "df_bal_lag_logscale = df_bal_nonull[\n",
    "    (df_bal_nonull['ebitda']<=df_bal_nonull['ebitda'].quantile(.75))&\n",
    "    (df_bal_nonull['ebitda']>=df_bal_nonull['ebitda'].quantile(.25))]\n",
    "\n",
    "df_bal_outlier_lag = df_bal_lag_logscale.copy()\n",
    "\n",
    "# lag\n",
    "var_tar_2 = ['ebitda']\n",
    "\n",
    "df_bal_lag_logscale = create_lag.create_lag(\n",
    "    df=df_bal_lag_logscale,\n",
    "    id_col='company',\n",
    "    time_col='year',\n",
    "    cols=var_tar_2,\n",
    "    lag_num=3\n",
    ")\n",
    "\n",
    "\n",
    "# cross_val\n",
    "cros_val_bal_lag_scale = exe(data=df_bal_lag_logscale)\n",
    "cros_val_bal_lag_scale.execute(n_splits=3, test_size = 1, test=False)"
   ],
   "id": "8f7b3b1e26fabeb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Randome_forest: ...\n",
      "Processing SVR: ...\n",
      "Processing XGBoost: ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    algo_used                                             params  \\\n",
       "162   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...   \n",
       "161   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...   \n",
       "165   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...   \n",
       "164   XGBoost  {'learning_rate': 0.05, 'max_depth': 10, 'n_es...   \n",
       "160   XGBoost  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...   \n",
       "..        ...                                                ...   \n",
       "166   XGBoost  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...   \n",
       "147       SVR                         {'C': 5, 'kernel': 'poly'}   \n",
       "145       SVR                         {'C': 1, 'kernel': 'poly'}   \n",
       "146       SVR                          {'C': 5, 'kernel': 'rbf'}   \n",
       "144       SVR                          {'C': 1, 'kernel': 'rbf'}   \n",
       "\n",
       "     mean_test_r2  mean_test_mape  mean_test_rmse  \n",
       "162      0.799615        0.275645    1.364858e+10  \n",
       "161      0.797950        0.280132    1.370560e+10  \n",
       "165      0.796160        0.282073    1.376367e+10  \n",
       "164      0.795318        0.284405    1.379238e+10  \n",
       "160      0.792076        0.296035    1.390668e+10  \n",
       "..            ...             ...             ...  \n",
       "166      0.570588        0.625389    1.999431e+10  \n",
       "147     -0.083794        0.770996    3.176621e+10  \n",
       "145     -0.083872        0.770999    3.176738e+10  \n",
       "146     -0.083892        0.771000    3.176767e+10  \n",
       "144     -0.083892        0.771000    3.176767e+10  \n",
       "\n",
       "[193 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_used</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_test_mape</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.799615</td>\n",
       "      <td>0.275645</td>\n",
       "      <td>1.364858e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.797950</td>\n",
       "      <td>0.280132</td>\n",
       "      <td>1.370560e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.796160</td>\n",
       "      <td>0.282073</td>\n",
       "      <td>1.376367e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.795318</td>\n",
       "      <td>0.284405</td>\n",
       "      <td>1.379238e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.792076</td>\n",
       "      <td>0.296035</td>\n",
       "      <td>1.390668e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.570588</td>\n",
       "      <td>0.625389</td>\n",
       "      <td>1.999431e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 5, 'kernel': 'poly'}</td>\n",
       "      <td>-0.083794</td>\n",
       "      <td>0.770996</td>\n",
       "      <td>3.176621e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'kernel': 'poly'}</td>\n",
       "      <td>-0.083872</td>\n",
       "      <td>0.770999</td>\n",
       "      <td>3.176738e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 5, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.083892</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>3.176767e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.083892</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>3.176767e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows  5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:48:05.514103Z",
     "start_time": "2025-07-31T03:48:04.240343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main model training\n",
    "\n",
    "import create_lag\n",
    "from sklearn.metrics import root_mean_squared_error as rmse, mean_absolute_percentage_error as mape, r2_score as r2\n",
    "# Train_test\n",
    "a = ttp.TrainTestPipe(data=df_bal_outlier_lag)\n",
    "df_input_fin, df_hold_fin = a.holdout_and_split(panel_col=['company', 'year'],\n",
    "                                                level=1)[0:2]\n",
    "\n",
    "# Processing data for training purpose\n",
    "df_input_fin.drop(columns='platform', inplace=True)\n",
    "df_hold_fin.drop(columns='platform', inplace=True)\n",
    "df_input_train = df_input_fin.reset_index()\n",
    "\n",
    "df_input_lagbalout = create_lag.create_lag(\n",
    "    df=df_input_train,\n",
    "    id_col='company',\n",
    "    time_col='year',\n",
    "    cols=['ebitda'],\n",
    "    lag_num=3\n",
    ")\n",
    "\n",
    "df_input_lagbalout.set_index(['company', 'year'], inplace=True)\n",
    "# Train_test_split\n",
    "idx_val = [2023,2022,2021]\n",
    "\n",
    "X_train = df_input_lagbalout[~df_input_lagbalout.index.get_level_values(1).isin(idx_val)].drop(columns='ebitda')\n",
    "y_train = df_input_lagbalout['ebitda'][~df_input_lagbalout.index.get_level_values(1).isin(idx_val)]\n",
    "X_val = df_input_lagbalout[df_input_lagbalout.index.get_level_values(1).isin(idx_val)].drop(columns='ebitda')\n",
    "y_val = df_input_lagbalout['ebitda'][df_input_lagbalout.index.get_level_values(1).isin(idx_val)]\n",
    "\n",
    "# Train model\n",
    "xgb_reg = XGBRegressor(\n",
    "    learning_rate = 0.05,\n",
    "    n_estimators = 100,\n",
    "    max_depth=3,\n",
    "    subsample=0.5\n",
    ")\n",
    "\n",
    "model = xgb_reg.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "print('-'*20, 'Training Model_score', '-'*20)\n",
    "print(f'RMSE: {rmse(y_train_pred, y_train):,.2f}')\n",
    "print(f'MAPE: {mape(y_train_pred, y_train):.2f}')\n",
    "print(f'R2: {r2(y_train_pred, y_train):.2f}')\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print('-'*20, 'Validating Model_score', '-'*20)\n",
    "print(f'RMSE: {rmse(y_pred, y_val):,.2f}')\n",
    "print(f'MAPE: {mape(y_pred, y_val):.2f}')\n",
    "print(f'R2: {r2(y_pred, y_val):.2f}')\n"
   ],
   "id": "839125e21939d85a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Training Model_score --------------------\n",
      "RMSE: 9,663,491,627.04\n",
      "MAPE: 0.18\n",
      "R2: 0.87\n",
      "-------------------- Validating Model_score --------------------\n",
      "RMSE: 14,585,114,168.59\n",
      "MAPE: 0.24\n",
      "R2: 0.70\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- CLoser inspection show that the chosen hyper-param cause overfitting\n",
    "- Solution:\n",
    "    + decrease n_estimators: 300 -> 100\n",
    "    + decrease max_depth: 6 -> 3\n",
    "- The result is shown as above"
   ],
   "id": "9104b6382d6618c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:51:35.614751Z",
     "start_time": "2025-07-31T03:51:34.759089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test on held-out set\n",
    "# data creation (add lags)\n",
    "lag_list = [2023, 2022, 2021]\n",
    "# get index of company from df_hold_fin\n",
    "u_company = df_hold_fin.index.get_level_values(0).unique()\n",
    "df_fin_lag_3 = df_input_fin[(df_input_fin.index.get_level_values(0).isin(u_company))&\n",
    "                            (df_input_fin.index.get_level_values(1).isin(lag_list))\n",
    "]\n",
    "\n",
    "# concat into df_hold_fin\n",
    "df_hold_fin_new = pd.concat([df_hold_fin, df_fin_lag_3], axis=0)\n",
    "abc = df_hold_fin_new.reset_index()\n",
    "df_hold_out = create_lag.create_lag(\n",
    "    df = abc,\n",
    "    id_col = 'company',\n",
    "    time_col = 'year',\n",
    "    cols = ['ebitda'],\n",
    "    lag_num = 3\n",
    ")\n",
    "df_hold_out.set_index(['company', 'year'], inplace=True)\n",
    "\n",
    "# Predict + result\n",
    "y_hold_pred = model.predict(df_hold_out.drop(columns='ebitda'))\n",
    "y_val_h = df_hold_out['ebitda']\n",
    "print('-'*20, ' Testing Model_score', '-'*20)\n",
    "print(f'RMSE: {rmse(y_hold_pred, y_val_h):,.2f}')\n",
    "print(f'MAPE: {mape(y_hold_pred, y_val_h):.2f}')\n",
    "print(f'R2: {r2(y_hold_pred, y_val_h):.2f}')"
   ],
   "id": "4c2e64a897ec3425",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  Testing Model_score --------------------\n",
      "RMSE: 12,458,954,615.85\n",
      "MAPE: 0.20\n",
      "R2: 0.77\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comment:\n",
    "- Metric on hold-out set is not too far from validation set (a little better)\n",
    "- This proves model's consistency in prediction"
   ],
   "id": "32bc231bc2f7aa31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Limitation of the model\n",
    "- Data input shortage: since the model returned best result when outliers are dropped based on IQR method, much outlier has been dropped in exchange for better prediction. However, this made the model less powerful in times of outlying or unexpected events that make ebitda abnormally high or low.\n",
    "- MECE of algorithm: the model only used most commonly applied algorithm instead of trying all available algorithms, risking missing some good algorithms."
   ],
   "id": "f24a2fd7585d0cbf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
